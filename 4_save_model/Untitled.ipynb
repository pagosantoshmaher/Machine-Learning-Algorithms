{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n",
      "Text total length: 6,101\n",
      "Distinct chars   : 56\n",
      "Total sequences  : 2,027\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/needyin/Documents/Indian-City-Name-Generator-master/indiancitynames.txt\"\n",
    "\n",
    "#Fixing maximum length of city names to be generated\n",
    "maxlen = 20\n",
    "\n",
    "X, Y, char_idx = \\\n",
    "    textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM RNN \n",
    "net = tflearn.input_data(shape=[None, maxlen, len(char_idx)])\n",
    "net = tflearn.lstm(net, 512, return_seq=True, dropout=0.5)\n",
    "net = tflearn.lstm(net, 512, dropout=0.5)\n",
    "net = tflearn.fully_connected(net, len(char_idx), activation='softmax')\n",
    "net = tflearn.regression(net,optimizer='adam', loss='categorical_crossentropy',\n",
    "                       learning_rate=0.001)\n",
    "\n",
    "#A deep neural network model for generating sequences.\n",
    "model = tflearn.SequenceGenerator(net, dictionary=char_idx,\n",
    "                              seq_maxlen=maxlen,\n",
    "                              clip_gradients=5.0,\n",
    "                              checkpoint_path='model_indian_cities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-8-ceefa82b9098>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-ceefa82b9098>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    n_epoch, run_id='indian_cities')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for i in range(10):\n",
    "    #Seed helps us start from the same place everytime\n",
    "    seed = random_sequence_from_textfile(path, maxlen)\n",
    "    #Fitting data to the sequence\n",
    "    model.fit(X, Y, validation_set=0.1, batch_size=128,\n",
    "          n_epoch, run_id='indian_cities')\n",
    "    print(\"\\n...TESTING...\")\n",
    "    print(\"-- Test with temperature of 1.2 --\")\n",
    "    \"\"\"Generate a sequence. Temperature is controlling the novelty of the created sequence, \n",
    "       a temperature near 0 will looks like samples used for training, \n",
    "       while the higher the temperature, the more novelty.\"\"\"\n",
    "    print(model.generate(30, temperature=1.2, seq_seed=seed))\n",
    "    print(\"-- Test with temperature of 1.0 --\")\n",
    "    print(model.generate(30, temperature=1.0, seq_seed=seed))\n",
    "    print(\"-- Test with temperature of 0.5 --\")\n",
    "    print(model.generate(30, temperature=0.5, seq_seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
